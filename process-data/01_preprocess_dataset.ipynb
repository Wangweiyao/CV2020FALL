{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_preprocess_dataset\n",
    "- This preprocess should be exectuted **ONLY** once. If you run the code second time it will overlap with the correct new_bbox.txt file, in that case you need to delete the whole dataset then copy and rename the original dataset and run the code again.\n",
    "- In UECFOOD100 dataset, most images have regular dimensions with (800, 600) while many of them have irregular dimensions which lead to troubles when I save the img data to a .npv file in the future. So this code used to preprocess the UECFOOD100 dataset in order to:\n",
    "    - Resize irregular images to (800, 600) and save them in place;\n",
    "    - Scale bounding boxes if image be resized and save them in a new txt file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    # Put first column (id) and second column (name) from category.txt into two lists\n",
    "    category_ids = []\n",
    "    category_names = []\n",
    "    with open(my_dataset_disk + '/' + category, 'r') as category_list:\n",
    "        for i, line in enumerate(category_list):\n",
    "            if i > 0:\n",
    "                line = line.rstrip('\\n')  # delete \\n in the end of th\n",
    "                # e line\n",
    "                line = line.split('\\t')\n",
    "                category_ids.append(int(line[0]))\n",
    "                category_names.append(line[1])\n",
    "\n",
    "    for id_index, id in enumerate(category_ids):\n",
    "        new_bbox_info = []\n",
    "        with open(my_dataset_disk + '/' + str(id) + '/' + bbox_info, 'r') as bbox_list:\n",
    "            for i, line in enumerate(bbox_list):\n",
    "                if i > 0:\n",
    "                    line = line.rstrip('\\n')\n",
    "                    line = line.split(' ')\n",
    "                    img_path = my_dataset_disk + '/' + str(id) + '/' + str(line[0]) + '.jpg'\n",
    "                    ori_img = Image.open(img_path)\n",
    "                    if ori_img.size != (800, 600):\n",
    "                        new_bbox = list(map(str, newbbox(ori_img.size, list(map(int, line[1:])), target_wh)))\n",
    "                        new_bbox.insert(0, str(line[0]))\n",
    "                        new_bbox_info.append(new_bbox)\n",
    "                        ori_img = ori_img.resize([800, 600], Image.ANTIALIAS)\n",
    "                        ori_img.save(img_path)\n",
    "                    else:\n",
    "                        new_bbox_info.append(line)\n",
    "        rewrite_bbox(id, new_bbox_info)\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newbbox(ori_size, oldbbox, target_wh):\n",
    "    new_bbox = np.squeeze(np.zeros((1, 4)))\n",
    "    wscale = target_wh[0] / ori_size[0]\n",
    "    hscale = target_wh[1] / ori_size[1]\n",
    "    new_bbox[0], new_bbox[2] = int(wscale * oldbbox[0]), int(wscale * oldbbox[2])\n",
    "    new_bbox[1], new_bbox[3] = int(hscale * oldbbox[1]), int(hscale * oldbbox[3])\n",
    "\n",
    "    if new_bbox[0] > 800:\n",
    "        new_bbox[0] = 800\n",
    "    if new_bbox[2] > 800:\n",
    "        new_bbox[2] = 800\n",
    "    if new_bbox[1] > 600:\n",
    "        new_bbox[1] = 600\n",
    "    if new_bbox[3] > 600:\n",
    "        new_bbox[3] = 600\n",
    "\n",
    "    assert (new_bbox[0], new_bbox[2] <= [target_wh[0], target_wh[0]])[1].all()\n",
    "    assert (new_bbox[1], new_bbox[1] <= [target_wh[1], target_wh[1]])[1].all()\n",
    "\n",
    "    return new_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_bbox(id, new_bbox_info):\n",
    "    print('rewriting category ' + str(id) + ' ...')\n",
    "    file = open(my_dataset_disk + '/' + str(id) + '/' + 'new_bb_info.txt', 'w')\n",
    "    file.write('img x1 y1 x2 y2\\n')  # header\n",
    "    for i in new_bbox_info:\n",
    "        file.write(i[0] + ' ' + i[1] + ' ' + i[2] + ' ' + i[3] + ' ' + i[4] + '\\n')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewriting category 1 ...\n",
      "rewriting category 2 ...\n",
      "rewriting category 3 ...\n",
      "rewriting category 4 ...\n",
      "rewriting category 5 ...\n",
      "rewriting category 6 ...\n",
      "rewriting category 7 ...\n",
      "rewriting category 8 ...\n",
      "rewriting category 9 ...\n",
      "rewriting category 10 ...\n",
      "rewriting category 11 ...\n",
      "rewriting category 12 ...\n",
      "rewriting category 13 ...\n",
      "rewriting category 14 ...\n",
      "rewriting category 15 ...\n",
      "rewriting category 16 ...\n",
      "rewriting category 17 ...\n",
      "rewriting category 18 ...\n",
      "rewriting category 19 ...\n",
      "rewriting category 20 ...\n",
      "rewriting category 21 ...\n",
      "rewriting category 22 ...\n",
      "rewriting category 23 ...\n",
      "rewriting category 24 ...\n",
      "rewriting category 25 ...\n",
      "rewriting category 26 ...\n",
      "rewriting category 27 ...\n",
      "rewriting category 28 ...\n",
      "rewriting category 29 ...\n",
      "rewriting category 30 ...\n",
      "rewriting category 31 ...\n",
      "rewriting category 32 ...\n",
      "rewriting category 33 ...\n",
      "rewriting category 34 ...\n",
      "rewriting category 35 ...\n",
      "rewriting category 36 ...\n",
      "rewriting category 37 ...\n",
      "rewriting category 38 ...\n",
      "rewriting category 39 ...\n",
      "rewriting category 40 ...\n",
      "rewriting category 41 ...\n",
      "rewriting category 42 ...\n",
      "rewriting category 43 ...\n",
      "rewriting category 44 ...\n",
      "rewriting category 45 ...\n",
      "rewriting category 46 ...\n",
      "rewriting category 47 ...\n",
      "rewriting category 48 ...\n",
      "rewriting category 49 ...\n",
      "rewriting category 50 ...\n",
      "rewriting category 51 ...\n",
      "rewriting category 52 ...\n",
      "rewriting category 53 ...\n",
      "rewriting category 54 ...\n",
      "rewriting category 55 ...\n",
      "rewriting category 56 ...\n",
      "rewriting category 57 ...\n",
      "rewriting category 58 ...\n",
      "rewriting category 59 ...\n",
      "rewriting category 60 ...\n",
      "rewriting category 61 ...\n",
      "rewriting category 62 ...\n",
      "rewriting category 63 ...\n",
      "rewriting category 64 ...\n",
      "rewriting category 65 ...\n",
      "rewriting category 66 ...\n",
      "rewriting category 67 ...\n",
      "rewriting category 68 ...\n",
      "rewriting category 69 ...\n",
      "rewriting category 70 ...\n",
      "rewriting category 71 ...\n",
      "rewriting category 72 ...\n",
      "rewriting category 73 ...\n",
      "rewriting category 74 ...\n",
      "rewriting category 75 ...\n",
      "rewriting category 76 ...\n",
      "rewriting category 77 ...\n",
      "rewriting category 78 ...\n",
      "rewriting category 79 ...\n",
      "rewriting category 80 ...\n",
      "rewriting category 81 ...\n",
      "rewriting category 82 ...\n",
      "rewriting category 83 ...\n",
      "rewriting category 84 ...\n",
      "rewriting category 85 ...\n",
      "rewriting category 86 ...\n",
      "rewriting category 87 ...\n",
      "rewriting category 88 ...\n",
      "rewriting category 89 ...\n",
      "rewriting category 90 ...\n",
      "rewriting category 91 ...\n",
      "rewriting category 92 ...\n",
      "rewriting category 93 ...\n",
      "rewriting category 94 ...\n",
      "rewriting category 95 ...\n",
      "rewriting category 96 ...\n",
      "rewriting category 97 ...\n",
      "rewriting category 98 ...\n",
      "rewriting category 99 ...\n",
      "rewriting category 100 ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "target_wh = [800, 600]\n",
    "my_dataset_disk = '/home/weiyao/data/UECFOOD100/'\n",
    "category = 'category.txt'\n",
    "bbox_info = 'bb_info.txt'\n",
    "preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
